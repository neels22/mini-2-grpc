# Mini-2 gRPC: Distributed Fire Air Quality Query System

A multi-process distributed system for querying fire air quality data using gRPC, featuring **chunked streaming**, **request control**, and intelligent data partitioning across 5 worker servers.

## üéØ Project Status: 100% Complete ‚úÖ

‚úÖ **Phase 1:** Data Partitioning (COMPLETE)  
‚úÖ **Phase 2:** Chunked Streaming & Request Control (COMPLETE)  
‚úÖ **Phase 2.5:** Performance Analysis (COMPLETE)  
‚úÖ **Single-Computer:** Fully Validated & Documented  
‚úÖ **Phase 3:** Multi-Computer Deployment (COMPLETE - 2 computers, 1.5ms latency)

---

## üöÄ Quick Start

### Run the Full System Test
```bash
./test_phase2.sh
```

This automated script:
- Starts all 6 servers
- Runs comprehensive tests
- Demonstrates chunked streaming, cancellation, and status tracking
- Shows server logs and statistics

**Press Enter when done to stop all servers.**

---

## üìö Documentation

| Document | Description |
|----------|-------------|
| `MULTI_COMPUTER_RESULTS.md` | **‚úÖ Multi-computer deployment results (2 machines)** |
| `SINGLE_COMPUTER_COMPLETE.md` | **‚úÖ Single-computer deployment guide** |
| `results/single_computer_analysis.md` | **‚úÖ Performance analysis & benchmarks** |
| `MULTI_COMPUTER_SETUP.md` | Multi-computer setup guide |
| `PROJECT_STATUS.md` | Overall project status and checklist |
| `PHASE1_DATA_PARTITIONING_COMPLETE.md` | Phase 1 technical details |
| `PHASE2_CHUNKED_STREAMING_COMPLETE.md` | Phase 2 technical details |
| `presentation-iteration-1.md` | Bug fixes and iterations |

---

## üèóÔ∏è System Architecture

```
                      Client
                        |
                        v
                  Gateway A (50051)
                  [Chunked Streaming]
                  [Request Control]
                   /            \
                  /              \
                 v                v
           Server B            Server E
        (Green Leader)       (Pink Leader)
           (50052)             (50055)
              |                /      \
              v               v        v
           Server C       Server D   Server F
           (Worker)       (Worker)   (Worker)
           (50053)        (50054)    (50056)
```

### Data Distribution
- **Server B:** 134K measurements (Aug 10-17)
- **Server C:** 243K measurements (Aug 18-26)
- **Server D:** 244K measurements (Aug 27-Sep 4)
- **Server E:** 245K measurements (Sep 5-13)
- **Server F:** 300K measurements (Sep 14-24)
- **Total:** 1.17M measurements, 0% overlap

### Query Traversal Algorithm

The system uses a **parallel post-order tree traversal** pattern:

**Query Propagation (Top-Down):**
1. Client ‚Üí Gateway A (root node)
2. Gateway A ‚Üí Team Leaders B & E (parallel broadcast)
3. Leader B ‚Üí Worker C
4. Leader E ‚Üí Workers D & F (parallel broadcast)

**Result Aggregation (Bottom-Up):**
1. Workers (C, D, F) query local data and return results to their leaders
2. Leaders (B, E) aggregate worker results with their own local data
3. Gateway A aggregates results from both team leaders
4. Gateway A streams chunked results to client

**Traversal Characteristics:**
- **Type:** Depth-first with post-order processing
- **Execution:** Parallel at each level (fan-out to children)
- **Aggregation:** Bottom-up (children complete before parent)
- **Complexity:** O(log n) depth for balanced tree, O(n) for visiting all nodes

**Example Query Flow:**
```
Query: "Find all PM2.5 measurements with AQI < 100"

Step 1: Client sends query to A
Step 2: A forwards to B and E (parallel)
Step 3: B forwards to C, E forwards to D and F (parallel)
Step 4: C returns 50K results to B
Step 5: D returns 60K results to E
Step 6: F returns 70K results to E
Step 7: B (adds own 30K) returns 80K total to A
Step 8: E (adds own 40K) returns 170K total to A
Step 9: A aggregates 250K total results
Step 10: A streams results in chunks to client
```

**Benefits:**
- **Parallelism:** Multiple servers process simultaneously
- **Load distribution:** Work divided across all servers
- **Scalability:** Can add more workers without changing traversal
- **Fault tolerance:** Leader can continue if one worker fails

---

## ‚ú® Key Features

### Phase 1: Data Partitioning
- ‚úÖ 6-process distributed system with gRPC
- ‚úÖ Intelligent data partitioning (no overlaps)
- ‚úÖ Hybrid C++ and Python servers
- ‚úÖ Configuration-driven design
- ‚úÖ Columnar data model (FireColumnModel)

### Phase 2: Chunked Streaming & Request Control
- ‚úÖ **Configurable chunk sizes** (100-5000 measurements/chunk)
- ‚úÖ **Progressive streaming** (data sent as ready, not all at once)
- ‚úÖ **Request cancellation** (cancel mid-query)
- ‚úÖ **Status tracking** (real-time progress monitoring)
- ‚úÖ **Client disconnect detection** (graceful cleanup)
- ‚úÖ **Memory optimization** (80% reduction vs bulk responses)

---

## üß™ Testing

### Basic Test Client
```bash
./venv/bin/python3 client/test_client.py
```

### Advanced Client (All Features)
```bash
./venv/bin/python3 client/advanced_client.py
```

Demonstrates:
- Chunked streaming with progress bars
- Mid-query cancellation
- Status tracking during query
- Progressive delivery with small chunks

---

## üîß Build & Setup

### Build C++ Servers
```bash
make clean
make servers
```

### Install Python Dependencies
```bash
pip install -r requirements.txt
```

### Rebuild Proto Files (if needed)
```bash
# Python
python3 -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. proto/fire_service.proto

# C++
protoc -I. --cpp_out=. --grpc_out=. --plugin=protoc-gen-grpc=`which grpc_cpp_plugin` proto/fire_service.proto
```

---

## üìä Performance Characteristics

### Chunking Strategy

| Chunk Size | Chunks (for 150K results) | Latency | Memory | Use Case |
|------------|---------------------------|---------|--------|----------|
| 100 | 1500 | High | Low | Progressive UX |
| 500 | 300 | Medium | Medium | Balanced |
| 1000 | 150 | Low | Medium | **Default** |
| 5000 | 30 | Very Low | High | Large queries |

### Memory Benefits
- **Before:** Gateway holds 1.17M measurements (200MB)
- **After:** Streams 1K at a time (~100KB per chunk)
- **Savings:** 80% memory reduction

---

## üéÆ Usage Examples

### Example 1: Simple Query
```python
import grpc
import fire_service_pb2, fire_service_pb2_grpc

channel = grpc.insecure_channel('localhost:50051')
stub = fire_service_pb2_grpc.FireQueryServiceStub(channel)

request = fire_service_pb2.QueryRequest(
    request_id=12345,
    filter=fire_service_pb2.QueryFilter(parameters=["PM2.5"]),
    require_chunked=True,
    max_results_per_chunk=1000
)

for chunk in stub.Query(request):
    print(f"Chunk {chunk.chunk_number + 1}/{chunk.total_chunks}")
    print(f"  Received {len(chunk.measurements)} measurements")
```

### Example 2: Query with Cancellation
```python
import threading, time

def run_query():
    for chunk in stub.Query(request):
        process(chunk)

# Start query
thread = threading.Thread(target=run_query)
thread.start()

# Cancel after 2 seconds
time.sleep(2)
cancel = fire_service_pb2.StatusRequest(request_id=12345, action="cancel")
stub.CancelRequest(cancel)
```

### Example 3: Status Monitoring
```python
# Check query progress
status = stub.GetStatus(
    fire_service_pb2.StatusRequest(request_id=12345, action="status")
)
print(f"Progress: {status.chunks_delivered}/{status.total_chunks}")
print(f"Status: {status.status}")
```

---

## üìÅ Project Structure

```
mini-2-grpc/
‚îú‚îÄ‚îÄ gateway/
‚îÇ   ‚îî‚îÄ‚îÄ server.py              # Gateway with chunked streaming
‚îú‚îÄ‚îÄ team_green/
‚îÇ   ‚îú‚îÄ‚îÄ server_b.py            # Python leader
‚îÇ   ‚îî‚îÄ‚îÄ server_c.cpp           # C++ worker
‚îú‚îÄ‚îÄ team_pink/
‚îÇ   ‚îú‚îÄ‚îÄ server_d.cpp           # C++ worker
‚îÇ   ‚îú‚îÄ‚îÄ server_e.py            # Python leader
‚îÇ   ‚îî‚îÄ‚îÄ server_f.cpp           # C++ worker
‚îú‚îÄ‚îÄ common/
‚îÇ   ‚îú‚îÄ‚îÄ FireColumnModel.hpp/.cpp  # C++ data model
‚îÇ   ‚îî‚îÄ‚îÄ fire_column_model.py      # Python data model
‚îú‚îÄ‚îÄ proto/
‚îÇ   ‚îî‚îÄ‚îÄ fire_service.proto     # gRPC definitions
‚îú‚îÄ‚îÄ client/
‚îÇ   ‚îú‚îÄ‚îÄ test_client.py         # Basic test
‚îÇ   ‚îî‚îÄ‚îÄ advanced_client.py     # Advanced demo
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îî‚îÄ‚îÄ process_[a-f].json     # Server configs
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ YYYYMMDD/              # CSV files by date
‚îî‚îÄ‚îÄ test_phase2.sh             # Automated test
```

---

## üéì Assignment Requirements Met

### Core Requirements
- ‚úÖ 6 processes with gRPC communication
- ‚úÖ Correct overlay topology (AB, BC, AE, EF, ED)
- ‚úÖ Both C++ and Python servers
- ‚úÖ Configuration-driven (no hardcoding)
- ‚úÖ Non-overlapping data partitions
- ‚úÖ Realistic data structures

### Critical Features (Emphasized in Assignment)
- ‚úÖ **Chunked/segmented responses** (not single bulk)
- ‚úÖ **Request cancellation** (client can cancel)
- ‚úÖ **Connection loss handling** (disconnect detection)
- ‚úÖ **Status tracking** (progress monitoring)
- ‚úÖ **Multi-computer deployment** (2 computers, 1.5ms latency)

---

## ‚úÖ Project Complete

### All Phases Completed
1. ‚úÖ **Performance Analysis** - Complete with benchmarks
2. ‚úÖ **Single-Computer Validation** - All tests passing
3. ‚úÖ **Bug Fixes** - Filter logic and gRPC message size
4. ‚úÖ **Documentation** - Comprehensive guides and analysis
5. ‚úÖ **Multi-Computer Deployment** - Successfully deployed on 2 computers
   - ‚úÖ Deployed on 2 physical machines (10.10.10.1, 10.10.10.2)
   - ‚úÖ Updated configs with actual IP addresses
   - ‚úÖ Tested cross-network performance (~1.5ms latency)
   - ‚úÖ Retrieved 421,606 measurements across network
   - ‚úÖ Documented in `MULTI_COMPUTER_RESULTS.md`

**Project Status: PRODUCTION READY** üéâ

**Performance Highlights:**
- 124,008 measurements/second (max throughput)
- 1.0s to first chunk (best latency)
- 5+ concurrent clients supported
- 100% success rate across all tests

---

## üèÜ What Makes This Strong

1. **Efficient Architecture**: 80% memory savings with partitioning
2. **Robust Streaming**: Progressive chunked delivery with cancellation
3. **Full Request Control**: Status tracking and disconnect handling
4. **Clean Code**: Separation of concerns, config-driven
5. **Comprehensive Testing**: Automated tests with feature demos
6. **Thorough Documentation**: Technical details and usage guides

---

## ü§ù Contributing

This is an academic project for the Mini-2 gRPC assignment.

---

## üìù License

Academic use only.

---

## üÜò Troubleshooting

See `QUICK_START_PHASE2.md` for common issues and solutions.

**Quick fix for most problems:**
```bash
# Kill all servers
pkill -f server_

# Rebuild
make clean && make servers

# Test again
./test_phase2.sh
```

---

**For detailed technical documentation, see the markdown files in the project root.**